from flask import Flask, request, jsonify
from flask_cors import CORS
import numpy as np
import faiss
import json
from openai import OpenAI
import os

app = Flask(__name__)
CORS(app)

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ğŸ“š Carrega os dados de todos os livros
def carregar_livro(nome_json, nome_faiss, livro_id):
    with open(nome_json, "r", encoding="utf-8") as f:
        referencias = json.load(f)
    index = faiss.read_index(nome_faiss)
    return {"referencias": referencias, "index": index, "id": livro_id}

sabiston = carregar_livro("referencias.json", "indice_capitulos.faiss", "Sabiston")
anatomia = carregar_livro("referencias_anatomia.json", "indice_anatomia.faiss", "Anatomia")
mattox = carregar_livro("referencias_mattox.json", "indice_mattox.faiss", "Mattox")

bases = [sabiston, anatomia, mattox]

# ğŸ§  Gera embedding
def gerar_embedding(texto):
    response = client.embeddings.create(
        input=texto,
        model="text-embedding-ada-002"
    )
    return np.array(response.data[0].embedding)

@app.route("/perguntar", methods=["POST"])
def perguntar():
    dados = request.get_json()
    pergunta = dados.get("pergunta")

    if not pergunta:
        return jsonify({"erro": "Pergunta nÃ£o fornecida."}), 400

    # ğŸŒ Traduz a pergunta para inglÃªs mÃ©dico
    traducao = client.chat.completions.create(
        model="gpt-4-0125-preview",
        messages=[
            {"role": "system", "content": "Traduza para inglÃªs mÃ©dico sem explicaÃ§Ãµes."},
            {"role": "user", "content": pergunta}
        ]
    ).choices[0].message.content.strip()

    embedding = gerar_embedding(traducao).reshape(1, -1)

    contexto = ""
    fontes_usadas = []

    # ğŸ” Consulta os 3 Ã­ndices
    for base in bases:
        _, indices = base["index"].search(embedding, 3)

        for i in indices[0]:
            trecho = base["referencias"][i]["texto"]
            capitulo = base["referencias"][i]["capitulo"]
            contexto += f"\n[{base['id']} â€“ {capitulo}]\n{trecho}\n"
            fontes_usadas.append(f"{base['id']} â€“ {capitulo}")

    # ğŸ“ Prompt com orientaÃ§Ã£o cientÃ­fica e detalhada
    prompt = f"""
VocÃª Ã© um assistente mÃ©dico especializado em Cirurgia Geral, altamente cientÃ­fico e baseado em evidÃªncias.  
Responda Ã  pergunta abaixo **usando exclusivamente** as informaÃ§Ãµes fornecidas no contexto.

Se houver informaÃ§Ãµes **conflitantes entre os livros**, destaque e compare as diferenÃ§as claramente,
**citado a fonte especÃ­fica abaixo de cada trecho**.

Organize sua resposta em **HTML bem formatado**, com tÃ­tulos, listas, parÃ¡grafos e negrito para facilitar a leitura.

Se a resposta nÃ£o estiver no contexto, responda exatamente:  
<b>Essa informaÃ§Ã£o nÃ£o estÃ¡ disponÃ­vel no material fornecido.</b>

---

<h3>Contexto:</h3>
<pre>{contexto}</pre>

<h3>Pergunta:</h3>
<p>{pergunta}</p>
"""

    resposta = client.chat.completions.create(
        model="gpt-4-0125-preview",
        messages=[
            {"role": "system", "content": prompt}
        ]
    )

    resposta_texto = resposta.choices[0].message.content.strip()

    # ğŸ“š Monta citaÃ§Ã£o das fontes
    fontes_unicas = sorted(set(fontes_usadas))
    citacao = "ReferÃªncias utilizadas: " + "; ".join(fontes_unicas)

    return jsonify({
        "resposta": resposta_texto,
        "referencia": citacao
    })

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8080)

